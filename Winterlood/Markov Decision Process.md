Markov Decision Process?
===

- 순차적 행동 결정 문제를 수학적으로 정의한것 이하 (MDP)

- MDP는 state, action, reward, state transition probability, discount factor, policy로 구성된다.

State
===

state란 Agent가 관찰 가능한 상태의 집합.

에이전트가 가질 수 있는 모든 상태의 집합을 S라고 하고, 시간을 t라고 할때 

에이전트의 상태 s`을 다음과 같이 나타내자.

S[t] = s`,{s in S}

